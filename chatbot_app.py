
import os
import streamlit as st
from dotenv import load_dotenv

from langchain.document_loaders import TextLoader, PDFMinerLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.llms import OpenAI


# Load biáº¿n mÃ´i trÆ°á»ng tá»« .env
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
question = st.text_input("ğŸ’¬ CÃ¢u há»i cá»§a báº¡n:")
llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
if question:
    try:
        prompt = f"CÃ¢u há»i: {question}"
        st.code(prompt)

        response = llm.invoke(prompt)
        st.success(response)
    except Exception as e:
        st.error(f"Lá»—i khi gá»i AI: {e}")
# Giao diá»‡n á»©ng dá»¥ng
st.set_page_config(page_title="AI TÆ° váº¥n TÃ i liá»‡u KhÃ¡ch hÃ ng", page_icon="ğŸ“„")
st.title("ğŸ“„ Táº£i tÃ i liá»‡u riÃªng vÃ  há»i AI")

# Sidebar - Nháº­p tÃªn khÃ¡ch hÃ ng
st.sidebar.header("ğŸ‘¤ ThÃ´ng tin khÃ¡ch hÃ ng")
if "customer_name" not in st.session_state:
    st.session_state.customer_name = ""

name_input = st.sidebar.text_input("Nháº­p tÃªn khÃ¡ch hÃ ng", value=st.session_state.customer_name)
if name_input:
    st.session_state.customer_name = name_input

# Hiá»ƒn thá»‹ chÃ o má»«ng
if st.session_state.customer_name:
    st.success(f"Xin chÃ o {st.session_state.customer_name}! Báº¡n muá»‘n há»i gÃ¬?")
else:
    st.info("Vui lÃ²ng nháº­p tÃªn Ä‘á»ƒ báº¯t Ä‘áº§u.")

# Khá»Ÿi táº¡o lá»‹ch sá»­ chat náº¿u chÆ°a cÃ³
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# B1: Nháº­p tÃªn (tÃ¹y chá»n, láº¡i láº§n ná»¯a cho giao diá»‡n chÃ­nh)
name = st.text_input("ğŸ‘¤ TÃªn khÃ¡ch hÃ ng (tuá»³ chá»n):")

# B2: Upload tÃ i liá»‡u
uploaded_file = st.file_uploader("ğŸ“ Táº£i file tÃ i liá»‡u (PDF hoáº·c TXT)", type=["txt", "pdf"])

# B3: Nháº­p cÃ¢u há»i
if st.session_state.customer_name:
    question = st.text_input(f"{st.session_state.customer_name} há»i AI:")
else:
    question = st.text_input("Báº¡n muá»‘n há»i gÃ¬?")

# B4: Xá»­ lÃ½ khi Ä‘á»§ thÃ´ng tin
if uploaded_file and question:
    # LÆ°u táº¡m file
    temp_path = f"temp_{uploaded_file.name}"
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getvalue())

    # Táº£i tÃ i liá»‡u
    if uploaded_file.name.endswith(".pdf"):
        loader = PDFMinerLoader(temp_path)
    else:
        loader = TextLoader(temp_path, encoding="utf-8")
    documents = loader.load()

    # TÃ¡ch tÃ i liá»‡u
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    docs = splitter.split_documents(documents)

    # Khá»Ÿi táº¡o vectorstore
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    db = Chroma.from_documents(docs, embeddings)

    # Táº¡o mÃ´ hÃ¬nh vÃ  chuá»—i tráº£ lá»i
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)
    chain = load_qa_chain(llm, chain_type="stuff")

    # Táº¡o context cÃ¡ nhÃ¢n hÃ³a
    context = f"KhÃ¡ch hÃ ng: {name}. " if name else ""
    answer = chain.run(input_documents=db.similarity_search(question), question=context + question)

    # Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i
    st.markdown("#### ğŸ¤– Tráº£ lá»i:")
    st.write(answer)

    # LÆ°u vÃ o lá»‹ch sá»­ chat
    st.session_state.chat_history.append(("KhÃ¡ch hÃ ng", question))
    st.session_state.chat_history.append(("AI", answer))

    # XÃ³a file táº¡m
    os.remove(temp_path)

# B5: LÆ°u lá»‹ch sá»­ chat
st.markdown("---")
if st.button("ğŸ’¾ LÆ°u lá»‹ch sá»­ chat"):
    if st.session_state.chat_history:
        chat_data = [
            {"NgÆ°á»i gá»­i": sender, "Ná»™i dung": message}
            for sender, message in st.session_state.chat_history
        ]
        df = pd.DataFrame(chat_data)
        df.to_csv("lich_su_chat.csv", index=False, encoding="utf-8-sig")
        st.success("âœ… ÄÃ£ lÆ°u vÃ o file lich_su_chat.csv")
    else:
        st.warning("â— ChÆ°a cÃ³ cuá»™c trÃ² chuyá»‡n nÃ o Ä‘á»ƒ lÆ°u.")

