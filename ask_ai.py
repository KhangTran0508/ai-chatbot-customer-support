import os
from dotenv import load_dotenv
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains.question_answering import load_qa_chain
from langchain.llms import OpenAI

# B1: Náº¡p API key
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# B2: Káº¿t ná»‘i láº¡i vector database Ä‘Ã£ lÆ°u
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
db = Chroma(persist_directory="chroma_db", embedding_function=embeddings)

# B3: HÃ m há»i AI
def ask_ai(question):
    # TÃ¬m nhá»¯ng Ä‘oáº¡n liÃªn quan nháº¥t tá»« tÃ i liá»‡u
    relevant_docs = db.similarity_search(question)

    # Táº¡o LLM (GPT)
    llm = OpenAI(temperature=0, openai_api_key=openai_api_key)

    # Táº¡o chuá»—i há»i-Ä‘Ã¡p
    chain = load_qa_chain(llm, chain_type="stuff")

    # Tráº£ lá»i dá»±a vÃ o tÃ i liá»‡u
    answer = chain.run(input_documents=relevant_docs, question=question)
    return answer

# âœ… DÃ¹ng thá»­
if __name__ == "__main__":
    while True:
        question = input("ğŸ’¬ Há»i AI: ")
        if question.lower() in ["exit", "quit"]:
            break
        print("ğŸ¤– Tráº£ lá»i:", ask_ai(question))
